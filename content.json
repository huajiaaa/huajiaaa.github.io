{"pages":[{"title":"about","text":"简单的程序猿. 邮箱: whj_elite@163.com 微信: by_wushen","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index-1.html"},{"title":"categories","text":"","link":"/categories/index.html"}],"posts":[{"title":"我为什么会惆怅","text":"中秋三天假，这么快就过去了 发现假期越长，临近假期结束时就越惆怅 大概是因为快乐而梦幻的时光这么快就结束，接下来又要面临挑战，反差太大，很难接受吧 不禁开始担心接下来的国庆节，在最后的一两天时，会有多失落啊 突然想起了《赤壁赋》： 于是饮酒乐甚，扣舷而歌之。 歌曰：“桂棹兮兰桨，击空明兮溯流光。 渺渺兮予怀，望美人兮天一方。” 客有吹洞箫者，倚歌而和之。 其声呜呜然，如怨如慕，如泣如诉，余音袅袅，不绝如缕。 舞幽壑之潜蛟，泣孤舟之嫠妇。 往往在欢乐的时光，想起即将要面对的难过的事情，会更难过吧 其实，我觉得文章中，苏子劝客的一番话，真的很扯淡 那为什么“客喜而笑，洗盏更酌”呢？ 面对如此真实的人生，不如此又能怎样呢，或许还不如享受当下 社会中，生活享受的人与生活煎熬的人，比例大概远远小于二与八 “肴核既尽，杯盘狼籍。相与枕藉乎舟中，不知东方之既白。” 看来我也是经常这样了，夜晚一个人在住处喝啤酒，看视频，真的是麻木的快乐，然后睡去…. 醒来时已经是第二天的九十点钟了 但是，麻木的快乐之后的生活，又会是怎样的呢, 该如何面对呢 ？ 这就是我为什么会惆怅","link":"/2019/09/15/2019-9-15/"},{"title":"Prometheus tsdb","text":"Prometheus 把监控数据存在本地磁盘的时间序列数据库中（ time series database, tsdb）, 同时也支持集成远程存储系统. Prometheus 的 tsdb 经历过两次大升级, 从 v1 升到 v2 , 从 v2 升到 v3, 其中每次升级都比原来的版本有着巨大的改善. 目前最新的版本是 v3 tsdb , 本文将对其进行介绍, 希望读者在读完本文后, 对 prometheus tsdb 整体设计能有比较清晰的认知、对自己感兴趣的实现细节能有一定的理解. 备注: 本文的内容是综合资料介绍以及个人理解总结出来的, 如果有理解不对或不准确的情况, 希望读者们能不吝指出. 数据库的选择/设计理念 &amp; Prometheus 的场景需求理念该选择哪款数据库, 或者一个数据库被设计成什么样, 取决与预期怎么使用它(场景). Prometheus 的场景样本点格式介绍1identifier -&gt; (t0, v0), (t1, v1), (t2, v2), (t3, v3), .... 其中, identifier 是一个 metric name 以及其所有标签的键值对, 例如： requests_total{path=”/status”, method=”GET”, instance=”10.0.0.1:80”} ti 表示时间点 vi 表示 ti 时刻该 identifier 的取值 metric name 也被视为一个标签, 用\\ _${metricName}_\\ 表示, 因此上述例子也可以表示为：{__name__=”requests_total”, path=”/status”, method=”GET”, instance=”10.0.0.1:80”} 场景需求 如上图所示, 其中, 横轴是时间 t, 纵轴是 identifier, 平面上的点是 v： 写需求 特别特别密集. 预期中, 一台 Prometheus 实例每秒钟应该能收集百万级别的样本点 只是纵向的写 读需求 相比于写, 读需求很少 对 Latency 要求较高 有按时间范围查询的需求, 且一般会涉及多个 identifier 的查询 越新的数据越有价值, 查询的需求也越高 k8s 环境下特有的现象—— series churn通常, metric 中都会有 instance 标签. 而在 k8s 环境下, 由于 pod 是经常变化的（比如滚动升级时）, 会导致「series churn」（不会翻译就不翻译了）, 如下图所示（即很多老 series 其实是不需要的）： 介绍完了 Prometheus 的场景特点以及对数据库的使用需求, 接下来介绍 Prometheus 所使用的 tsdb 是怎样做的. 整体架构 其中, (t, v) 即为采集的一个样本点（sample） Head block 在内存中 灰色的 block 在磁盘中（并且是不可变的） M-map 为磁盘中两个小时以内的数据在内存中的映射 WAL 是预写日志（Write-ahead logging） 接下来对监控样本点的生命周期进行简单介绍. 样本点的生命周期Prometheus 新采集的样本都会存到 Head block, 其中每一个 series 会存到唯一对应的压缩单元(即 chunk) 里. 为了防止 Prometheus 挂了导致内存中的数据丢失, 新采集到的数据还会写到预写日志中.如下图： 备注：样本点在存入 chunk 时, 通过 labels 的哈希值来获得或创建对应的 series chunk. 当 chunk 中存了 120 个样本或该 chunk 已满 2h 时, 将创建出一个新的 chunk, 老的 chunk 视为 “已满”. ps: 如果 15s 采集一次, 则每 30min 会满一次. 如下图所示: 红色的是新创建的 chunk, 黄色的是老的 chunk. 自 Prometheus v2.19.0 之后（我们目前使用的是 v2.20.0）, 当一个 chunk “已满” 时, 它就会被刷新到磁盘中, 并从磁盘中进行内存映射（memory-map）, 仅在内存中存储一个它的引用. 有了内存映射, 可以再需要的时候通过引用动态地将 chunk 加载到内存中, 这是操作系统提供的特性, 参考: https://en.wikipedia.org/wiki/Mmap. 当 Head 中的数据跨度达到 3h 时（mmap 中数据的时间跨度）, 则最久的两个小时的数据(即上图的 1~4)将被压缩成一个 persistent block. 此时, 相关的 WAL 和索引数据也被删除. 再看一次这个图： 每个 block 是按时间序列排序的. 当查询多个 block 中, 会从很多 block 中读出对应的数据, 然后再合并成一个整体的结果, 这个合并过程显然是有代价的. 因此引入了压缩(compaction)操作：即将一个或多个 block 合并成一个更大的 block. 在压缩的过程中还可以修改现有数据, 例如删除「已被删除」的数据, 或者重新构造样本块以提高查询性能. 压缩的时机与设定的步长有关: 假设 block 为保存 2h 的数据, 如果步长设置为 3, 则会将三个 2h 的合成一个 6h 的block, 将三个 6h 的合成一个 18h 的block. 当 block 中存储的数据达到了所设置的最大保留时间时, 它们即会被删除. 以上就是关于监控样本点的生命周期的简单介绍. 磁盘上的数据格式本节将分别对 Head Block 和 block 进行介绍. Head blockFile上文介绍的 mmap 中的 chunks 保存在名为 chunks_head 的目录下, 文件序列与 WAL 中的相似. 如下图: 12345678910data├── chunks_head| ├── 000001| └── 000002└── wal ├── checkpoint.000003 | ├── 000000 | └── 000001 ├── 000004 └── 000005 其中, 文件（比如上图中的 000001）的 最大 size 是 128M. 每个的文件格式如下所示: 123456789101112131415┌──────────────────────────────┐│ magic(0x0130BC91) &lt;4 byte&gt; │├──────────────────────────────┤│ version(1) &lt;1 byte&gt; │├──────────────────────────────┤│ padding(0) &lt;3 byte&gt; │├──────────────────────────────┤│ ┌──────────────────────────┐ ││ │ Chunk 1 │ ││ ├──────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────┤ ││ │ Chunk N │ ││ └──────────────────────────┘ │└──────────────────────────────┘ 其中. magic number 是可以唯一标识一个文件时 head_chunk 的数字 (类似 Java 中的咖啡宝贝..) version 告诉我们如何解码文件中的 chunks (version 怎么告诉我们如何解码？version 其实是编码/格式的版本) padding 是为了将来可能需要的选项而预留出来的 备注：magic 在接下来其他的数据格式中会多次出现, 用途一致, 就不赘述了. Chunk一个 chunk 的格式如下所示： 123┌─────────────────────┬───────────────────────┬───────────────────────┬───────────────────┬───────────────┬──────────────┬────────────────┐| series ref &lt;8 byte&gt; | mint &lt;8 byte, uint64&gt; | maxt &lt;8 byte, uint64&gt; | encoding &lt;1 byte&gt; | len &lt;uvarint&gt; | data &lt;bytes&gt; │ CRC32 &lt;4 byte&gt; │└─────────────────────┴───────────────────────┴───────────────────────┴───────────────────┴───────────────┴──────────────┴────────────────┘ 其中, series ref 是用于访问内存中的序列的 id, 即上文中 mmap 中的引用 mint 是该 chunk 中 series 的最小时间戳 max 是该 chunk 中 series 的最大时间戳 encoding 是压缩该 chunk 时使用的编码 len 是此后的字节数 data 是压缩后的数据 CRC32 是用于检查数据完整性的校验和 Head Block 通过 series ref, 以及 mint、maxt 就可以实现不访问磁盘就选择 chunk. 其中, ref 是 8 bytes, 前 4 个字节告诉了 chunk 存在哪个文件中（file number）， 后四个字节告诉了 chunk 在该文件中的偏移量. Persistent Block1234567891011121314151617data├── 01EM6Q6A1YPX4G9TEB20J22B2R| ├── chunks| | ├── 000001| | └── 000002| ├── index| ├── meta.json| └── tombstones├── chunks_head| ├── 000001| └── 000002└── wal ├── checkpoint.000003 | ├── 000000 | └── 000001 ├── 000004 └── 000005 上图中的 01EM6Q6A1YPX4G9TEB20J22B2R 即是一个 Persistent Block. 其中, meta.json：block 的元信息 chunks：chunk 的原始数据 index：block 的索引 tombstones：删除标记, 用于查询该 block 时排除样本 01EM6Q6A1YPX4G9TEB20J22B2R：block id （与 UUID 主要的区别是它是字典序的, 见https://github.com/oklog/ulid） 接下来分别进行介绍. meta.jsonmeta 中包含了整个 block 所需的所有元数据, 如下图： 123456789101112131415161718{ &quot;ulid&quot;: &quot;01EM6Q6A1YPX4G9TEB20J22B2R&quot;, &quot;minTime&quot;: 1602237600000, &quot;maxTime&quot;: 1602244800000, &quot;stats&quot;: { &quot;numSamples&quot;: 553673232, &quot;numSeries&quot;: 1346066, &quot;numChunks&quot;: 4440437 }, &quot;compaction&quot;: { &quot;level&quot;: 1, &quot;sources&quot;: [ &quot;01EM65SHSX4VARXBBHBF0M0FDS&quot;, &quot;01EM6GAJSYWSQQRDY782EA5ZPN&quot; ] }, &quot;version&quot;: 1} 其中, version：索引格式的版本，告诉我们如何解析该 meta 文件 ulid：尽管该 block 的目录名是 ULID, 但是实际上已 meta 中的 ulid 为准，目录名可以是任何名称. minTime/maxTime：该 block 中所有 chunk 的 min 和 max 时间戳 stats：该 block 中存储的时间序列、样本和 chunk 的数量 compaction：该 block 的历史 level：该 block 多少代了 sources：由哪些 blocks 合并而成, 如果是从 Head block 创建来的, 则 sources 设置为自己的 ULID Chunks123456789101112131415┌──────────────────────────────┐│ magic(0x85BD40DD) &lt;4 byte&gt; │├──────────────────────────────┤│ version(1) &lt;1 byte&gt; │├──────────────────────────────┤│ padding(0) &lt;3 byte&gt; │├──────────────────────────────┤│ ┌──────────────────────────┐ ││ │ Chunk 1 │ ││ ├──────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────┤ ││ │ Chunk N │ ││ └──────────────────────────┘ │└──────────────────────────────┘ 与 Head 中的文件格式差不多, 不赘述了. 但有个区别是 Head 中的 file 最大 size 是 128M, 这里的 file 最大是 512M. 每个 chunk 的格式如下图所示： 123┌───────────────┬───────────────────┬──────────────┬────────────────┐│ len &lt;uvarint&gt; │ encoding &lt;1 byte&gt; │ data &lt;bytes&gt; │ CRC32 &lt;4 byte&gt; │└───────────────┴───────────────────┴──────────────┴────────────────┘ 与 head_chunk 差不多, 区别是少了 series ref、mint、maxt. 在 Head_chunk 中需要这些附加信息是为了 prometheus 重启时能够创建内存索引, 但是在持久化 block 中, 这些信息在 index 文件中存储了, 因此不再需要.同样通过 reference 来访问这些 chunk. indexindex 是倒排索引, 它包含了查询该 block 所需要的所有信息. 它不与任何其它 block 或外部实体共享数据, 这使得可以在没有任何依赖的情况下读取/查询该 block.(这个结构比较复杂, 但不要慌 : )) 它的宏观视图如下所示： 123456789101112131415161718192021222324252627┌────────────────────────────┬─────────────────────┐│ magic(0xBAAAD700) &lt;4b&gt; │ version(1) &lt;1 byte&gt; │├────────────────────────────┴─────────────────────┤│ ┌──────────────────────────────────────────────┐ ││ │ Symbol Table │ ││ ├──────────────────────────────────────────────┤ ││ │ Series │ ││ ├──────────────────────────────────────────────┤ ││ │ Label Index 1 │ ││ ├──────────────────────────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────────────────────────┤ ││ │ Label Index N │ ││ ├──────────────────────────────────────────────┤ ││ │ Postings 1 │ ││ ├──────────────────────────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────────────────────────┤ ││ │ Postings N │ ││ ├──────────────────────────────────────────────┤ ││ │ Label Offset Table │ ││ ├──────────────────────────────────────────────┤ ││ │ Postings Offset Table │ ││ ├──────────────────────────────────────────────┤ ││ │ TOC │ ││ └──────────────────────────────────────────────┘ │└──────────────────────────────────────────────────┘ 其中, magic：用来唯一标识某个文件是 index 文件 version：告诉我们如何解析该文件 TOC：是该 index 文件的入口处（就像目录一样, 记录了各部分的页码） TOC123456789101112131415┌─────────────────────────────────────────┐│ ref(symbols) &lt;8b&gt; │ -&gt; Symbol Table├─────────────────────────────────────────┤│ ref(series) &lt;8b&gt; │ -&gt; Series├─────────────────────────────────────────┤│ ref(label indices start) &lt;8b&gt; │ -&gt; Label Index 1├─────────────────────────────────────────┤│ ref(label offset table) &lt;8b&gt; │ -&gt; Label Offset Table├─────────────────────────────────────────┤│ ref(postings start) &lt;8b&gt; │ -&gt; Postings 1├─────────────────────────────────────────┤│ ref(postings offset table) &lt;8b&gt; │ -&gt; Postings Offset Table├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt; │└─────────────────────────────────────────┘ 格式如上图所示, 主要是告诉我们各索引开始的位置. TOC 是固定大小的，因此文件的最后 52 个字节就是 TOC. Symbol Table符号表,记录了所有 series 的标签和值的字符串的非重复有序列表.比如 一个 series 是 {a=”y”, x=”b”}, 则符号会是 “a”, “b”, “x”, “y” . 12345678910111213┌────────────────────┬─────────────────────┐│ len &lt;4b&gt; │ #symbols &lt;4b&gt; │├────────────────────┴─────────────────────┤│ ┌──────────────────────┬───────────────┐ ││ │ len(str_1) &lt;uvarint&gt; │ str_1 &lt;bytes&gt; │ ││ ├──────────────────────┴───────────────┤ ││ │ . . . │ ││ ├──────────────────────┬───────────────┤ ││ │ len(str_n) &lt;uvarint&gt; │ str_n &lt;bytes&gt; │ ││ └──────────────────────┴───────────────┘ │├──────────────────────────────────────────┤│ CRC32 &lt;4b&gt; │└──────────────────────────────────────────┘ len：该部分的字节数symbols：符号的数量str_i：utf8 编码的字符串, 每个字符串前都有 len 前缀; 随后是字符串的原始值索引中的其他部分可以为任何字符串引用此符号表, 由此减小 index 的大小. （通过偏移量 str_i 引用, 当需要实际的字符串时, 则通过偏移量从表中获取） Series123456789┌───────────────────────────────────────┐│ ┌───────────────────────────────────┐ ││ │ series_1 │ ││ ├───────────────────────────────────┤ ││ │ . . . │ ││ ├───────────────────────────────────┤ ││ │ series_n │ ││ └───────────────────────────────────┘ │└───────────────────────────────────────┘ 此部分存了当前 block 中所有 series 的信息, 按照标签的字典序排序. 每个 series 都是 16 byte 对齐的, 使得 series 开始处的偏移量能够被 16 整除. 因此,将 series 的 id 设置为 offset/16, offset 指向 series 的开头. 每当要访问某个 series 时, 可以直接通过 id * 16 来获取在 index 中的位置. Label Offset Table &amp; Label Index i这两个是耦合的, 因此应该放在一起介绍. 但是, 目前这两个已经不再使用, 只是为了向后兼容而编写的. 所以本文暂且没有介绍. Postings Offset Table &amp; Postings iPostings iposting 其实就是 series id. (之所以叫 posting 其实是因为在倒排索引的 “世界” 里, 文档 id 常被成为 posting, 而在当前的场景下, 一个 series 可以被视为一个文档, 因此把 series id 当做 posting.) 单个 posting 其实代表了一个 posting list, 其格式如下所示: 12345678910111213┌────────────────────┬────────────────────┐│ len &lt;4b&gt; │ #entries &lt;4b&gt; │├────────────────────┴────────────────────┤│ ┌─────────────────────────────────────┐ ││ │ ref(series_1) &lt;4b&gt; │ ││ ├─────────────────────────────────────┤ ││ │ ... │ ││ ├─────────────────────────────────────┤ ││ │ ref(series_n) &lt;4b&gt; │ ││ └─────────────────────────────────────┘ │├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt; │└─────────────────────────────────────────┘ 其中, len 和 CRC32 的作用大家都已经很熟悉了. entries 是该 list 中的 posting 数量; 其次是 entries 个有序的 posting（即 series id, 即引用）. posting list 中存储的内容介绍： 假设有两个时间序列: {a=”b”, x=”y1”} with series ID 120 {a=”b”, x=”y2”} with series ID 145 可以看到 a=”b” 出现在两个 series 中, ; 而 x=”y1”, x=”y2” 分别各自出现在一个 series 中. 此时 posting list 中会存: posting 1： // a=”b” 在两个 series 都出现了 120 145 posting 2：//x =”y1” 120 posting 3: //x =”y2” 145 Postings Offset Table12345678910111213141516┌─────────────────────┬──────────────────────┐│ len &lt;4b&gt; │ #entries &lt;4b&gt; │├─────────────────────┴──────────────────────┤│ ┌────────────────────────────────────────┐ ││ │ n = 2 &lt;1b&gt; │ ││ ├──────────────────────┬─────────────────┤ ││ │ len(name) &lt;uvarint&gt; │ name &lt;bytes&gt; │ ││ ├──────────────────────┼─────────────────┤ ││ │ len(value) &lt;uvarint&gt; │ value &lt;bytes&gt; │ ││ ├──────────────────────┴─────────────────┤ ││ │ offset &lt;uvarint64&gt; │ ││ └────────────────────────────────────────┘ ││ . . . │├────────────────────────────────────────────┤│ CRC32 &lt;4b&gt; │└────────────────────────────────────────────┘ 其中, len 和 CRC32 的作用大家都已经很熟悉了. entries 是该表中的条目数. n 永远是 2, 代表了接下来字符串的数量（label name 和 label value 俩字符串）. 接下来是 label name 和 label value 的原始值. 由于标签对通常并不多, 因此能够负担得起在此处存储原始字符串，从而避免间接访问符号表（符号表的主要用途在于被 Series 部分使用）. PS：我们公司目前的标签对还是很多的. offset 代表了该键值对在 postings list 中的偏移量. 以上述例子中, name=”a”, value=”b” 的偏移量将指向 posting list 中的 [120, 145] name=”x”, value=”y1” 的偏移量将指向 posting list 中的 [120] Postings Offset Table 中的条目是根据 label name 和 label value 排序的, 因此可以对所需的标签对进行二分查找（这也是此处存储实际字符串以便于更快访问标签值的另一个原因）. postings list 与 postings offset table 构成了倒排索引. tombstones Tombstones（墓碑） 是删除标记, 它告诉我们在读取/查询时可以忽略哪个 time series 的哪段时间范围. 12345678910111213┌────────────────────────────┬─────────────────────┐│ magic(0x0130BA30) &lt;4b&gt; │ version(1) &lt;1 byte&gt; │├────────────────────────────┴─────────────────────┤│ ┌──────────────────────────────────────────────┐ ││ │ Tombstone 1 │ ││ ├──────────────────────────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────────────────────────┤ ││ │ Tombstone N │ ││ ├──────────────────────────────────────────────┤ ││ │ CRC&lt;4b&gt; │ ││ └──────────────────────────────────────────────┘ │└──────────────────────────────────────────────────┘ magic、version、CRC 的作用大家都很熟悉了. Tombstone 的格式如下： 123┌────────────────────────┬─────────────────┬─────────────────┐│ series ref &lt;uvarint64&gt; │ mint &lt;varint64&gt; │ maxt &lt;varint64&gt; │└────────────────────────┴─────────────────┴─────────────────┘ 其它还有一些内容也属于 tsdb 中需要了解的范畴, 比如数据压缩的方法等, 但不是目前必须要知道的内容, 因此本文中暂时没有介绍, 感兴趣的话可以自行去了解. 结合上述分析和部分源码, 查询 tsdb 时发生了什么？前置介绍一个 Block 即是一个 NewBlockQuerier.见下 1424 行. 1234567891011121314151617181920212223242526272829303132// Querier returns a new querier over the data partition for the given time range.func (db *DB) Querier(_ context.Context, mint, maxt int64) (storage.Querier, error) { var blocks []BlockReader db.mtx.RLock() defer db.mtx.RUnlock() for _, b := range db.blocks { if b.OverlapsClosedInterval(mint, maxt) { blocks = append(blocks, b) } } if maxt &gt;= db.head.MinTime() { blocks = append(blocks, NewRangeHead(db.head, mint, maxt)) } blockQueriers := make([]storage.Querier, 0, len(blocks)) for _, b := range blocks { q, err := NewBlockQuerier(b, mint, maxt) //为 block 创建 NewBlockQuerier, 构造函数见下一个代码块 if err == nil { blockQueriers = append(blockQueriers, q) continue } // If we fail, all previously opened queriers must be closed. for _, q := range blockQueriers { // TODO(bwplotka): Handle error. _ = q.Close() } return nil, errors.Wrapf(err, &quot;open querier for block %s&quot;, b) } return storage.NewMergeQuerier(blockQueriers, nil, storage.ChainedSeriesMerge), nil} 12345678// NewBlockQuerier returns a querier against the block reader and requested min and max time range.func NewBlockQuerier(b BlockReader, mint, maxt int64) (storage.Querier, error) { q, err := newBlockBaseQuerier(b, mint, maxt) // newBlockBaseQuerier 构造函数见下一个代码块 if err != nil { return nil, err } return &amp;blockQuerier{blockBaseQuerier: q}, nil} 12345678910111213141516171819202122232425262728func newBlockBaseQuerier(b BlockReader, mint, maxt int64) (*blockBaseQuerier, error) { indexr, err := b.Index() if err != nil { return nil, errors.Wrap(err, &quot;open index reader&quot;) } chunkr, err := b.Chunks() if err != nil { indexr.Close() return nil, errors.Wrap(err, &quot;open chunk reader&quot;) } tombsr, err := b.Tombstones() if err != nil { indexr.Close() chunkr.Close() return nil, errors.Wrap(err, &quot;open tombstone reader&quot;) } if tombsr == nil { tombsr = tombstones.NewMemTombstones() } return &amp;blockBaseQuerier{ mint: mint, maxt: maxt, index: indexr, chunks: chunkr, tombstones: tombsr, }, nil} Querier 通过调用 Select 方法返回 series set123456789// Querier provides querying access over time series data of a fixed time range.type Querier interface { LabelQuerier // Select returns a set of series that matches the given label matchers. // Caller can specify if it requires returned series to be sorted. Prefer not requiring sorting for better performance. // It allows passing hints that can help in optimising select, but it&apos;s up to implementation how this is used if used at all. Select(sortSeries bool, hints *SelectHints, matchers ...*labels.Matcher) SeriesSet} 在 Select 时, 会根据 PromQL 中的标签条件进行匹配, 最终调用 Postings 方法获得 series ids12345678910111213141516171819202122func (q *blockQuerier) Select(sortSeries bool, hints *storage.SelectHints, ms ...*labels.Matcher) storage.SeriesSet { mint := q.mint maxt := q.maxt p, err := PostingsForMatchers(q.index, ms...) // 在这一步即获得了 postings, 即 series ids, 见下一个代码块 if err != nil { return storage.ErrSeriesSet(err) } if sortSeries { p = q.index.SortedPostings(p) } if hints != nil { mint = hints.Start maxt = hints.End if hints.Func == &quot;series&quot; { // When you&apos;re only looking up metadata (for example series API), you don&apos;t need to load any chunks. return newBlockSeriesSet(q.index, newNopChunkReader(), q.tombstones, p, mint, maxt) } } return newBlockSeriesSet(q.index, q.chunks, q.tombstones, p, mint, maxt)} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// PostingsForMatchers assembles a single postings iterator against the index reader// based on the given matchers. The resulting postings are not ordered by series.func PostingsForMatchers(ix IndexReader, ms ...*labels.Matcher) (index.Postings, error) { var its, notIts []index.Postings // See which label must be non-empty. // Optimization for case like {l=~&quot;.&quot;, l!=&quot;1&quot;}. labelMustBeSet := make(map[string]bool, len(ms)) for _, m := range ms { if !m.Matches(&quot;&quot;) { labelMustBeSet[m.Name] = true } } for _, m := range ms { if labelMustBeSet[m.Name] { // If this matcher must be non-empty, we can be smarter. matchesEmpty := m.Matches(&quot;&quot;) isNot := m.Type == labels.MatchNotEqual || m.Type == labels.MatchNotRegexp if isNot &amp;&amp; matchesEmpty { // l!=&quot;foo&quot; // If the label can&apos;t be empty and is a Not and the inner matcher // doesn&apos;t match empty, then subtract it out at the end. inverse, err := m.Inverse() if err != nil { return nil, err } it, err := postingsForMatcher(ix, inverse) //见下一个代码块 if err != nil { return nil, err } notIts = append(notIts, it) } else if isNot &amp;&amp; !matchesEmpty { // l!=&quot;&quot; // If the label can&apos;t be empty and is a Not, but the inner matcher can // be empty we need to use inversePostingsForMatcher. inverse, err := m.Inverse() if err != nil { return nil, err } it, err := inversePostingsForMatcher(ix, inverse) //见下下个代码块 if err != nil { return nil, err } its = append(its, it) } else { // l=&quot;a&quot; // Non-Not matcher, use normal postingsForMatcher. it, err := postingsForMatcher(ix, m) //见下一个代码块 if err != nil { return nil, err } its = append(its, it) } } else { // l=&quot;&quot; // If the matchers for a labelname selects an empty value, it selects all // the series which don&apos;t have the label name set too. See: // https://github.com/prometheus/prometheus/issues/3575 and // https://github.com/prometheus/prometheus/pull/3578#issuecomment-351653555 it, err := inversePostingsForMatcher(ix, m) //见下下个代码块 if err != nil { return nil, err } notIts = append(notIts, it) } } // If there&apos;s nothing to subtract from, add in everything and remove the notIts later. if len(its) == 0 &amp;&amp; len(notIts) != 0 { k, v := index.AllPostingsKey() allPostings, err := ix.Postings(k, v) //最终都会调用 Postings 方法 if err != nil { return nil, err } its = append(its, allPostings) } it := index.Intersect(its...) for _, n := range notIts { it = index.Without(it, n) } return it, nil} 12345678910111213141516171819202122232425262728293031323334353637383940414243func postingsForMatcher(ix IndexReader, m *labels.Matcher) (index.Postings, error) { // This method will not return postings for missing labels. // Fast-path for equal matching. if m.Type == labels.MatchEqual { return ix.Postings(m.Name, m.Value) //最终都会调用 Postings 方法 } // Fast-path for set matching. if m.Type == labels.MatchRegexp { setMatches := findSetMatches(m.GetRegexString()) if len(setMatches) &gt; 0 { sort.Strings(setMatches) return ix.Postings(m.Name, setMatches...) } } vals, err := ix.LabelValues(m.Name) if err != nil { return nil, err } var res []string lastVal, isSorted := &quot;&quot;, true for _, val := range vals { if m.Matches(val) { res = append(res, val) if isSorted &amp;&amp; val &lt; lastVal { isSorted = false } lastVal = val } } if len(res) == 0 { return index.EmptyPostings(), nil } if !isSorted { sort.Strings(res) } return ix.Postings(m.Name, res...)} 123456789101112131415161718192021222324// inversePostingsForMatcher returns the postings for the series with the label name set but not matching the matcher.func inversePostingsForMatcher(ix IndexReader, m *labels.Matcher) (index.Postings, error) { vals, err := ix.LabelValues(m.Name) if err != nil { return nil, err } var res []string lastVal, isSorted := &quot;&quot;, true for _, val := range vals { if !m.Matches(val) { res = append(res, val) if isSorted &amp;&amp; val &lt; lastVal { isSorted = false } lastVal = val } } if !isSorted { sort.Strings(res) } return ix.Postings(m.Name, res...)} 正式开始吧如 “前置介绍” 中所说, 在查询时最终都会调用 block 的 postings 方法. 接下来分别对 Head Block 中的 postings 方法和 Persistent Block 中的 postings 方法进行介绍. Head#Postings12345678// Postings returns the postings list iterator for the label pairs.func (h *headIndexReader) Postings(name string, values ...string) (index.Postings, error) { res := make([]index.Postings, 0, len(values)) for _, value := range values { res = append(res, h.head.postings.Get(name, value)) //直接通过 postings.Get 获得 } return index.Merge(res...), nil} 123456789101112131415// Get returns a postings list for the given label pair.func (p *MemPostings) Get(name, value string) Postings { var lp []uint64 p.mtx.RLock() l := p.m[name] if l != nil { lp = l[value] } p.mtx.RUnlock() if lp == nil { return EmptyPostings() } return newListPostings(lp...)} 123456789// MemPostings holds postings list for series ID per label pair. They may be written// to out of order.// ensureOrder() must be called once before any reads are done. This allows for quick// unordered batch fills on startup.type MemPostings struct { mtx sync.RWMutex m map[string]map[string][]uint64 ordered bool} 总结：Head 的 Postings 方法很简单, 直接通过 mmap 即可获得某个标签键值对的 postings. Block#Postings1234567func (r blockIndexReader) Postings(name string, values ...string) (index.Postings, error) { p, err := r.ir.Postings(name, values...) // 调用 Index 的 Postings if err != nil { return p, errors.Wrapf(err, &quot;block: %s&quot;, r.b.Meta().ULID) } return p, nil} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104func (r *Reader) Postings(name string, values ...string) (Postings, error) { if r.version == FormatV1 { // 我们现在应该是 V2, 可忽略 e, ok := r.postingsV1[name] if !ok { return EmptyPostings(), nil } res := make([]Postings, 0, len(values)) for _, v := range values { postingsOff, ok := e[v] if !ok { continue } // Read from the postings table. d := encoding.NewDecbufAt(r.b, int(postingsOff), castagnoliTable) _, p, err := r.dec.Postings(d.Get()) if err != nil { return nil, errors.Wrap(err, &quot;decode postings&quot;) } res = append(res, p) } return Merge(res...), nil } e, ok := r.postings[name] // Reader 的内容见下一个代码块, 即获得该 label 在 offset table 中的开始位置 if !ok { return EmptyPostings(), nil } if len(values) == 0 { return EmptyPostings(), nil } res := make([]Postings, 0, len(values)) skip := 0 valueIndex := 0 for valueIndex &lt; len(values) &amp;&amp; values[valueIndex] &lt; e[0].value { // 遍历直至找到开始的位置. // 根据上文的宏观介绍, offset table 中 label 的 key 和 value 都是有序的 // 因此 values[valueIndex] &lt; e[0].value 即代表查询的标签值在当前 block 中不存在/未命中 // Discard values before the start. valueIndex++ } for valueIndex &lt; len(values) { value := values[valueIndex] //二分查找 i := sort.Search(len(e), func(i int) bool { return e[i].value &gt;= value }) if i == len(e) { // We&apos;re past the end. break } if i &gt; 0 &amp;&amp; e[i].value != value { // Need to look from previous entry. i-- } // Don&apos;t Crc32 the entire postings offset table, this is very slow // so hope any issues were caught at startup. d := encoding.NewDecbufAt(r.b, int(r.toc.PostingsTable), nil) d.Skip(e[i].off) // Iterate on the offset table. var postingsOff uint64 // The offset into the postings table. for d.Err() == nil { if skip == 0 { // These are always the same number of bytes, // and it&apos;s faster to skip than parse. skip = d.Len() d.Uvarint() // Keycount. d.UvarintBytes() // Label name. skip -= d.Len() } else { d.Skip(skip) } v := d.UvarintBytes() // Label value. postingsOff = d.Uvarint64() // Offset. for string(v) &gt;= value { if string(v) == value { // 如果标签值匹配上了 // Read from the postings table. d2 := encoding.NewDecbufAt(r.b, int(postingsOff), castagnoliTable) _, p, err := r.dec.Postings(d2.Get()) // 解码 if err != nil { return nil, errors.Wrap(err, &quot;decode postings&quot;) } res = append(res, p) // postings 加入 result list } valueIndex++ if valueIndex == len(values) { break } value = values[valueIndex] } if i+1 == len(e) || value &gt;= e[i+1].value || valueIndex == len(values) { // Need to go to a later postings offset entry, if there is one. break } } if d.Err() != nil { return nil, errors.Wrap(d.Err(), &quot;get postings offset entry&quot;) } } return Merge(res...), nil} 123456789101112131415161718192021type Reader struct { b ByteSlice toc *TOC // Close that releases the underlying resources of the byte slice. c io.Closer // Map of LabelName to a list of some LabelValues&apos;s position in the offset table. // The first and last values for each name are always present. postings map[string][]postingOffset // For the v1 format, labelname -&gt; labelvalue -&gt; offset. postingsV1 map[string]map[string]uint64 symbols *Symbols nameSymbols map[uint32]string // Cache of the label name symbol lookups, // as there are not many and they are half of all lookups. dec *Decoder version int} 总结： 通过 postings[name] 获得 label name 所对应的 values 的在 offset table 中开始的位置 首先根据上述 “开始的位置” 的标签的值过滤掉未命中的 label values（因为有序） 遍历所有需要查询的标签值 在 offset table 中进行二分查找, 找到当前标签值在 offset table 中的上界（上界是标签值, 或者前一个是标签值, 或者 miss） 通过 toc 找到 posting offet table， 通过上边找到的 offset 获得对应的 series ids 通过 series ids 反解出原始的标签值 原始标签值与要查找的标签值对比 如果相等则把该 series id 加入到 res 中 不相等则说明二分查找 miss merge res 参考资料 https://prometheus.io/docs/prometheus/latest/storage/ https://fabxc.org/tsdb/ https://ganeshvernekar.com/blog/prometheus-tsdb-the-head-block https://ganeshvernekar.com/blog/prometheus-tsdb-persistent-block-and-its-index https://github.com/prometheus/prometheus/blob/master/tsdb/docs/format/index.md https://github.com/prometheus/prometheus/blob/master/tsdb/head.go https://github.com/prometheus/prometheus/blob/2c4a4548a8382f7c8966dbfda37f34c43151e316/storage/series.go https://github.com/prometheus/prometheus/tree/a282d2509971174301408c5a5f96946c478dfb0f/tsdb/index","link":"/2020/11/29/Prometheus-tsdb/"},{"title":"聊聊 &quot;道理&quot;","text":"这个话题其实起源于我的一次 “自我反思”, 当时我又一次在想: 当前的生活状态自己满意吗? (答案显然是不那么满意的 要一直这样下去吗? (答案显然是不要 这个时候矛盾开始显现了: 既然我一直很笃定地认为 “不能再这样下去了”, 那为什么一直没有行动呢? 想到了王阳明的 “知行合一”，我个人的理解大概就是: 知道但做不到, 等于不知道。 按照这个理念，我关于 “要一直这样下去吗” 的答案其实是: 要一直这样下去。 这让我变得疑惑了, 难道我不想变得更好吗? 我当然一直都很想啊, 怎么可能不想呢? 是我错了嘛还是他的观点是错的? 后来仔细想想，”知行合一” 或许是基于结果论来说的, “一个道理你不知道” 与 “一个道理你知道却没做”, 它们的结果其实是一样的, 因为那个能改变结果的事情没有做, 所以才是 “知道做不到, 等于不知道”。 从这个角度来看的话, 其实 “想减肥就得少吃多动” 的道理我也根本不知道, 因为没能做到。 想起了 “后会无期” 中的经典台词: 听过很多道理,依然过不好这一生。 为什么会这样呢？ 因为道理不适用于现实社会吗？ 如果从 “知行合一” 的角度来看, 就说得通了: 因为道理 “听过” 但不等于 “做过”, 做不到的道理也就等于没听过而已。 还好是这样，道理还是有效的。 可惜是这样，道理知道了也很难做到。","link":"/2021/01/11/%E8%81%8A%E8%81%8A%E9%81%93%E7%90%86/"},{"title":"Software Complexity：Naming","text":"原文：https://alexoliveira.cc/software-naming.html 并非逐句逐词，而是根据自己的理解进行了翻译。 There are only two hard things in Computer Science: cache invalidation and naming things. Phil Karlton 当我们尝试阅读和理解软件系统时，我们希望代码通顺，希望它能用业务领域中的词汇，清晰而准确地传达意图和关系。代码虽然只写一次，但是会被阅读很多次。 烂代码使人迷惑，它是在 “代码对作者有意义，对读者没意义” 的假设或认知下编写的。如果一段代码需要在别人的帮助下才能被理解，或者需要花费与之不相称的巨大努力后才能看懂它在做什么，那就是烂代码。 我们如何才能写出好的代码呢？ 不管想在任何领域取得成功，第一步就是要对领域内的组成元素，以及元素对人和环境的影响进行充分的了解。优秀的电影导演在看了无数个小时的电影后，能将电影领域中的元素和规律总结出来，然后操纵它们来有效地讲故事。同样的道理也适用于小说家、音乐家、棋手。 类似的，程序猿应该也能够通过观察业务领域并发现其元素和规律。 领域中的元素有些很明显，但有些则不然，这就是问题所在：为这些元素起一个名字并非易事，因为有些元素在现实中并不存在；亦或者是有些元素存在，但缺少每个人都能理解的名称。 有些命名使元素个性化，而有些则将元素聚合在一起；有些命名表示抽象，而另一些则使事物具体化；有些命名表明了角色，有些表明性质…… 许多人取不好名字只是因为缺乏灵感。 给组件和元素命名元素的类型以及元素间的关系有一个完整的宇宙。有些是在同一层级（如左手、右手），有些则是包含的关系（如公司、员工）。有些元素依赖于另外的元素（如支付、支付方式）。而有些元素则会产生其他的元素（如账单、付款）。 为了揭示概念和它们的名字，我们从问一些简单的问题开始。 问题1/3这是什么房间？ 通过这个家具来看，很可能客厅。 基于一个组件，我们知道我们所在的房间的名称，这很简单。 问题2/3这是什么房间？ 根据这个物体，我们可以比较肯定的说这是洗手间。 看到规律了吗？房间的名称是一个标签， 它定义了房间里的内容。有了这个标签，我们不需要查看容器内部就能够知道里边有什么元素。这使得我们能够建立起我们的第一个推论： 推论1: 容器名是关于其元素的函数（container name is a function of its elements） 注意，这其实就是鸭子类型：它有床吗? 那很可能是卧室。 反过来也是正确的：如果我们谈论的是一间卧室，那么它很可能有一张床。这使我们能够定义第二个推论： 推论2: 我们可以根据容器名推断出它有哪些元素（we can infer components based on the container name） 很明显，我们有了一些规则，让我们尝试把它们应用到隔壁的房间。 问题3/3这是什么房间？ 如果我们的系统是一所房子，那么在同一个房间里的一张床和一个马桶使得这个房间的定义变得非常非常模糊。 这时使用推论1和推论2好像就很难给房间命名，或许我们可以给他命名为 “奇怪室”。 根据我的经验，大多数时候命名的难题都是由于糟糕的建模造成的。当软件中的元素没有被连贯且合乎逻辑地被引入时，有一个好的命名几乎是不可能的。由于排期很紧，开发者被迫先想到什么就交付什么。 在家里，我们把具有相同功能、目的和意图的元素放在一起。这使得组织变得更容易，然而通过混淆这些元素的职责，我们不能确定作者想要什么元素或者如何使用这些元素，从而阻塞了流程。 推论3: 容器定义的清晰程度与其组件的紧密程度成正比（the clarity with which a container is defined is proportional to how closely related its components are） 当组件间相互关联时，就更容易找到一个好的命名。而当事物间没有关联时，起名就变得很难。 这里所说的 “关联” 可以是它们的功能、目的、策略、类型或其他的任何方面。在讨论标准之前，”关联” 这个词本身没有多大意义。我们在后边的章节就会讲到它。 请注意，如果我们的系统是一座监狱，而不是一所房子，这些假设就会颠倒过来。在这个场景下，读者很容易就能认出这个房间是一件牢房。这就引出了另外一个重要推论： 推论4: 一个容器的定义受上下文约束（a container definition is constrained to its context） 当我们只关注容器的定义时，这个推论是显而易见的，但其实还有一个问题：系统常常没有定义上下文。 当大多数代码结构是打平的时，上下文的定义就会丢失，从而淡化了容器之间的区别。这导致 “提示某段代码该去哪里去看的提示不存在”，所以感觉代码像是随机的。 可以想象，如果所有的业务逻辑都打平在一个类中实现，那基本是不可读的。 由于缺少层级的概念，这样的实现相当于变相鼓励了开发人员在任何地方添加代码。就像 Alan Kay 所说的: 如今的大多数软件很像埃及金字塔，由数百万块砖头堆砌而成，没有任何的结构完整性，只是由蛮力和成千上万的奴隶完成的。 Most software today is very much like an Egyptian pyramid with millions of bricks piled on top of each other, with no structural integrity, but just done by brute force and thousands of slaves. 例1: HTTP domain and a car HTTP 是一个有 request 和 responses 的域。如果我们往里边放进了一个叫做 “汽车” 的组件，我们就不能再称它为 HTTP 了。在这种情况下，它变得令人困惑。 123456789public interface WhatIsAGoodNameForThis { /* methods for a car */ public void gas(); public void brake(); /* methods for an HTTP client */ public Response makeGetRequest(String param); } 例2: Coupling through words 一个常见的模式是在类名后加个 “Builder” 或者其他 er 结尾的单词，比如 SomethingBuilder、UserBuilder,、AccountBuilder、AccountCreator、UserHelper、JobPerformer…… 通过类名来判断，我们可能得出三个推论： 首先，类名中的动词 build 意味着它是一个函数（当然实际上 build 只是类名中的片段）。函数负责做事情，类则包含实体和上下文。函数不是实体，如果没有很好的定义实体，代码库很快就会演变成过程代码，因为它没有充分利用 “class pattern” 的初衷（面向对象）。 其次，它有两个内部的、隐式的实体，即 User 和 Builder，这意味着可能违背封装原则。我们的意思是 User 不应该负责生成新的 User。 第三，它意味着 Builder 可以访问 User 的内部的函数，因为它们毕竟是互相绑在一起的。 我已经看到整个代码库都充斥着这种代码。有一些复杂的模式试图解决这个问题，比如 Factory Pattern。许多时候它们是很有用的，但当我们遇到建模问题时，我们最好是修复它，而不是给它打个绷带/创可贴。 例 3: Base 让我们看一个真实代码的例子。它是 Ruby gem 的代码 I18n（为了简洁起见，只列出类和方法名） 123456class Base def config def translate def locale_available?(locale) def transliterateend 在这个例子中， Base 并没有传达出什么意思。它可以 config，可以 translate，以及可以确定 local 是否可用。它做了一些不同的、不相关的事情。 例4: names guiding design 当我们谈到命名如何指导我们的设计时，Discourse 上有几个例子，其中一个很有意思。 123456789class PostAlerter def notify_post_users def notify_group_summary def notify_non_pm_users def create_notification def unread_posts def unread_count def group_statsend “PostAlerter” 的命名暗示了它的功能可能是：”alert” 某人关于某个 “post”。然而，unread_posts、unread_count、和 group_stats 显然是要处理其他东西，这使得这个类名不适合它所做的事情。将这三个方法转移到一个名为 PostsStatistics 的类中，使得这一切变得更加清晰和可预测。 123456789101112class PostAlerter def notify_post_users def notify_group_summary def notify_non_pm_users def create_notificationendclass PostsStatistics def unread_posts def unread_count def group_statsend 例5: ambiguous names Spring 框架中也有几个例子，一个组件做了太多的事情，因此需要起一个类似我们上文中提到的 “奇怪室” 的名称。 可以看这个例子： 1234567class SimpleBeanFactoryAwareAspectInstanceFactory { public ClassLoader getAspectClassLoader() public Object getAspectInstance() public int getOrder() public void setAspectBeanName(String aspectBeanName) public void setBeanFactory(BeanFactory beanFactory)} 例6: good naming, for a change 不好的命名我们已经说的够多了，我们再来看看好的命名。 D3 的 arc 命名就很好，例如： 123456789101112export default function() { /* ... */ arc.centroid = function() { /* ... */ } arc.innerRadius = function() { /* ... */ } arc.outerRadius = function() { /* ... */ } arc.cornerRadius = function() { /* ... */ } arc.padRadius = function() { /* ... */ } arc.startAngle = function() { /* ... */ } arc.endAngle = function() { /* ... */ } arc.padAngle = function() { /* ... */ } return arc;} 这些方法中的每一个都是完全有意义的：它们都是以弧的名称命名的。我喜欢下边这张图，因为它太简洁了。 接下来讲讲当我们起名遇到麻烦时，可以怎么办。 办法1: 拆分 何时使用：你不能为一个类或者组件找到一个好的名字，但是你已经有了一些独立的概念，并希望为它们的分组找到合适的名称。 这个方法由两部组成： 明确已有的概念 把它们分开 在 “马桶 + 床” 的场景中，我们把不同的东西分开：把床推到左边，把马桶推到右边。现在我们有了两个独立的东西，我们终于可以用自然的方式来推理（房间的名称）了。 当你不能为某个东西找到一个好名字时，很可能是因为有不仅一个东西摆在你面前。而且，正如你现在知道的，给多个事物起名字是很难的。当遇到麻烦时，试着找出你面前的东西由哪些部分和行为组成。 举例 我们有一个未命名的类，它里边包含了 request、response、headers、URLs、body、caching 和 timeout。把所有这些从主类中分离出来，只剩下组件 Request、 Response、 Headers、 URLs、 ResponseBody、 Cache、 Timeout。如果摆在我们面前的只是这些类的名称，我们可以相当肯定地假设我们正在处理一个 web 请求。 HTTPClient 这个命名很适合 web 请求组件。 当代码难写时，不要直接考虑整体，先想想部分。 办法2: 发现新的概念 何时使用：当一个类不简洁或不条理清晰的时候。 发现新的概念需要有业务领域的知识。当软件中使用与业务相同的术语时，就形成了一种普遍存在的语言（Evans，2003），这种语言允许来自不同专业领域的专业人士使用相同的术语。 例1: 将组件封装到一个新概念中 几年前，一家公司差点失去一份大合同，因为团队在发布新功能和修复 bug 方面进展缓慢。 这个电子商务市场通过多个支付网关，根据不同国家的不同规则向学生收取费用，需求相当复杂。 当我看到这个收费代码 PaymentGateway 时，我震惊于它是多么地复杂，有多个依赖项，包括：User、 UserAddress、 CreditCard、 BillingAddress、 SellerAddress、 LineItems、 Discounts，等等。它的构造函数是巨大的，这种复杂性使得添加新规则变得困难，因为修改一个东西就会破坏其他东西，并且需要我们更改所有网关适配器。 这个问题已经超出了支付的范畴。通过在 messaging class 中再次聚合这些数据的方式，他们向学生发送了电子邮件。技术支持部门有自己的数据大盘屏幕，他们第三次聚合了这些数据，除了这个特定的地方使用了一个名为 Aggregator 的类（如果没有上下文，这个词就没有意义）。我们必须要点什么来解决这个架构上的障碍。 为了解决这个问题，我先是做了一个思维练习。以下是思维的过程： （假设我就身处在 PaymentGateway 的世界里，在我面前是我需要你( PaymentGateway)为我收费的细节。如果这是一张桌子，我会把这些文件整理好，我可能会把这些文件称为发票（Invoices）。所以，如果我创建一个名为 Invoice 的类会怎么样呢？它只不过是所有这些细节的集合，这样网关就不需要知道这些规则是如何起作用的，因为 Invoice 类会搞定这些？不用注入一大堆对象，我只给你一个就行？ Here I am, with these details about things I need you (the PaymentGateway) to charge for me. If this was a desk, I’d have these papers organized and I’d probably call them Invoices. So what if I created one class called Invoice, which is nothing more than the aggregation of all these other details, such that the gateway doesn’t need to know how those rules are done because Invoice will? Instead of injecting a million objects, I just hand one over to you? Invoice 一词在系统中的任何地方都没有使用。我们花了一个月的时间进行重构，一旦我们完成了重构，我们就能够更快地修改软件。 Invoice 是一个 “概念” 的一个很好的例子，它是来自许多源的数据的集合，大多数人都知道它是什么。最后的解决方案是通过外观模式](https://en.wikipedia.org/wiki/Facade_pattern)把 Invoice 类单独注入到网关中，并隐藏了其他类和对象。 好的命名不仅仅是使用华丽的辞藻，而是要准确地写出需要表达的内容。 例2: 基于业务领域的变体名称（另一种叫法） 在一个新开发的拼车项目中，我们从头开始设计了这个系统。在研究交通解决方案的过程中，描述”某个人在某一天从出发地到目的地的一段旅程”的合适词汇是 trip，而这类人则被称为 ride。我们发布了词汇表，这样公司的其他人就可以讨论和共享相同的通用语言。 在项目推出后，我们的客户总是把 trip 叫成 rides。很快我们就遇到了问题，在经历了巨大的痛苦之后，我们决定是时候重构了，于是我们把 trips 重构成 rides，把 rides重构成 carpools。这解决了一家公司说两种不同语言的问题。 例3: 抽象级别 一个人说”移动右腿、然后左腿、然后右腿“；另一个人说”走路“。两者的意思相同，但后者更抽象。 理想情况下，随着代码越来越接近公共 API，它就越努力匹配业务上的命名方式。而当它接近数据库甚至金属时，它则更倾向于使用与上下文相关的物理上的命名。在这两者之间， 有着从更多抽象到更少抽象的变化趋势。 在我们公司，业务人员会说 post Tweet，因此在公共 API 中，像 postTweet()这样的名称比 makeHttpRequest() 这样的名称更有意义。在一个有更多技术服务的公司里，后者则更合适。 其次，需要考虑特殊性。postTweet()是非常具体的，而 makeHttpRequest()则非常通用，它可以应用于 Facebook 或其他基本上任何涉及 HTTP 的东西。一个通用的名字可以很容易地被重复使用，但代价是含糊不清。这就解释了为什么框架代码与业务软件代码如此不同。 例4: 泛化 很久以前，CMS 有 news、 history、 videos、 articles、 pages 等数据库表，它们中的大多数都有相同的列：title、summary 和 text。不同的是，videos 表有额外的属性，比如如 url(嵌入 YouTube )；history 表有着 date 属性，这样页面就会按年显示历史时间列表。所有这些表看起来都像是副本，各处都有一些细微差异，添加新功能需要重新编写大量的样板代码。 我将所有这些表聚合成一个名为 contents 的外键，这个外键指向了 sections 表，sections 表中包含了 news、history、videos 等。现在，只写一个 contents 代码就足够了。 多年后，一位朋友不得不编写一个小型的 CMS，我建议他采用相同的方法。 一旦完成了用于管理内容的表单，实现任何内容所需的时间是原先所需时间的 1/N，因为对于相同类型的每个新部分，它都已经完成了。 通过给它另一个名字使其泛化可以提高开发效率。 办法3: 分组的标准（对应上文所说的 “关联” 标准）何时使用：当各组件命名很好，但彼此间不搭配的时候 组件可以根据各种标准进行分组，包括物理性质、经济、情感、社会，以及在软件中最常用的标准——功能。 相框是根据情感因素来分组的，产品是根据经济动机来分组的。沙发和电视放在同一个房间里，它们是根据功能标准组合在一起，因为都有相同的功能或目的——提供休闲。 在软件世界里，我们倾向于把组件按照功能分组。如果把你的项目文件列表列出来，你可能会发现其中有 contollers/、models/、models/、adapters/、templates/ 等。 但是，有些时候这些分组可能让你感觉不那么舒适，这时就是重新评估模块间的结构的最佳时机了。 例: 根据策略分组 有一个用于自动把用户操作归档的库，它基于代码生成一个规范文件(例如 API Blueprint)， lints 文件(以保证格式正确)，并上传到云(例如 S3)。 基于文档的格式，将自动做出各种后续决策。选择 Blueprint API 将会使用不同的 linter、不同的 tester 以及不同的 API 元素转换器。在这里，根据一个输入将所有这些不同的功能分组的关键是策略。 因此，这个库包含了一个名为 Strategy 的模块，用于将文件格式、检查器、文档测试器和存储程序组合在一起。这使得这个库能够将 uploaders、parsers 和 command-line 等普通的文件操作与业务的核心策略分开。 利用上下文每个应用都有不同的上下文，以及其中的每个模块、每个类、甚至每个功能。仅 User 一词就可能有多个语义，比如它可以表示系统的用户，但也可能是数据库表，或者第三方服务的身份凭据。 lib/billing/user 与 lib/booking/user 不同，但他们都是 user。 假设每个容器（比如模块）都是一个桶。在他们内部，组件与外部世界隔离。你可以随意给这些类命名，这使得不需要绞尽脑汁地为一个普通的事物寻找深奥的名字。 微服务（许多孤立的桶）比单体结构（一个大桶，里边有许多小桶）更有说服力的一点是，它强制约束了每个服务的职责，因为这样你就不能轻易地把完全不相关的东西放在一起。 Billing 存在于 BillingApp 中， booking 存在于 BookingApp 中，等等。 在单体架构中，虽然这些各自的服务名称可以是简单的模块名称，但并不是每个人都有保持整洁的原则。 例: 命名空间 Mark 正在开发一个广告平台，需要生成成千上万则广告，然后将其发送给 AdWords、Facebook 和 Bing，所有这些都通过图形用户界面进行管理。 Mark 从一个叫做 Ad 的实体开始，这个实体很快就变得臃肿起来。AdWords 的广告有 headline_part1 和 headline_part2，而 Facebook 没有，而 Bing 只有 headline。他需要想办法分割他的实体。他思考了不同的上下文，以及如何利用语言的命名空间的特性来表达这一点。他设计出了下边的结构： Adwords::Ad: 代表 Adwords 中的一个广告对象，它有 Adwords 特有的属性，逻辑可以包含在这个类中 Facebook::Ad: 与之前一样，它有 Facebook 特有的属性以及逻辑 Bing::Ad: 与上边一样 RemoteAdService::Ad: 这是Adwords::Ad、 Facebook::Ad、 Bing::Ad 与系统其他部分之间的服务接口。这意味着这三个类有着相同的 public API，从而使系统可以利用多态的特性 Database::Ad: 这是 ads 表的 ORM，它使用 ActiveRecord、DataMapper 或其他自定义的方式来实现 GUI::Ad: 表示在 UI 中显示广告所需要的属性。它可能具有 “展示” 和 “国际化” 的功能 API:Ad: 广告的 HTTP endpoint 有着自己的自定义属性，因此这里有一个序列化的逻辑是合理的 根据上下文，单词可以有不同的含义，当我们利用上下文时，我们可以为组件选择更简单的单词。 在这个例子中，我们不需要做任何复杂的动作来找到这些组件的名称， 因为它们都是一个东西——广告（ad）。 无意义的命名和旧词新义随着时间的推移，名字不断演变，获得了新的意义。 Helper: helper 是支持应用程序主要目标的函数。但是，定义应用程序的主要目标的标准是什么？应用程序中的一切都应该支持应用程序的主要目标。 在实践中，它们被集中在一个不自然的分组中，以提供一些复杂的、常用的操作的可重用性。它们往往会有特性依恋（Feature Envy）问题，因为需要访问其他组件的内部数据才能工作。它们是找不到合适的命名时的借口。 Base: 在很久以前的 c# 中，命名为 Base 的类是一种约定，即在没有更好的名称时可以使用，从而被其它类继承。举个例子，Automobile 和 Bicycle 的父类是 Base 而不是 Vehicle。尽管微软建议避免使用这个名字（Cwalina，2009），但这个词还是渗入进了 Ruby 的世界，最显著的例子是 ActiveRecord。直到今天，我们仍然将 Base 视为开发人员找不到类名时起的类名。 Base 的变体包括 Common 和 Utils。例如， JSON Ruby gem Common 类具有 parse、 generate、 load 和 jj 方法，但这里的 common 真正的意思是什么？ Tasks: 在 JavaScript 社区中有一个调用异步函数（tasks）的浪潮。它从 task.js 开始，这个术语甚至在原始库不存在的时候也被使用。 你可能解释说，某个命名虽然没太有意义，但团队中的每个人都理解它的意思。 那就好。 但是，如果有某个新人加入这个团队，并认为这个很久以来就存在的命名是一坨垃圾时，你感觉如何？ 我曾经参与过一个项目，其中一个类的名字是… 你们猜猜看… Atlanta（亚特兰大） 是的， Atlanta！ 草他妈的 Atlante！没人知道，也没人告诉我为什么会叫这个名字！ 沟通 现实存在于人类的思想中，而不是其他任何地方。 “Reality exists in the human mind and nowhere else.” George Orwell 我相信，善于沟通的做法是一种利他主义行为，我们在提高沟通技能上所付出的努力与我们对他人的关心程度有关。我们希望人们容易被（我们）理解，我们希望消除摩擦和阻碍。 其次，我们希望别人理解我们。通过认同 “接收方能收到消息是发送方的责任”，我们构建了一个共情的环境。这是双赢的局面。没有任何借口可以不刻意练习我们的沟通技巧——除非你生活在丛林中。 通过写作，我们可以提升阅读能力。而同理心的练习可能会让人筋疲力尽。但没办法，生活就是这样，熟能生巧。 参考文献Cwalina, Krzysztof. 2009. Framework Design Guidelines: Conventions, Idioms, and Patterns for Reusable .NET Libraries, Second Edition. Boston: Pearson Education, Inc. 206. Evans, Eric. 2003. Domain-Driven Design: Tackling Complexity in the Heart of Software. Boston: Addison-Wesley Professional.","link":"/2022/01/01/Naming/"},{"title":"信条","text":"好像每个大学都有校训，每家公司也都有文化标语（忘记贴切的词语了），比如猿辅导的公司文化是：审思聆听，简宜累进。 我在想，这些真的有用吗？ 这些对于所有学生、所有员工都有效吗？我觉得不太可能，因为学生入学一所学校（员工入职一家公司）肯定不是因为对校训/企业文化所认同。 那到底作用到了谁的身上呢？我相信，对于领导或高管应该或多或少会有一些影响的；对于制定者来说，更应该是意义深远（因为这些就是他认为非常重要的，以至于要时刻提醒自己和”同僚”）。 我想，或许该给自己找一个信条（座右铭）了。其一，是希望它真的能够时刻提醒自己；其二，如果以后真的有那么一个或几个人，我想要把我的信条分享给 ta，ta 需要是认同的。 我对自己信条的期望是：首先必须是我自己非常认同的；其次要符合我的自身情况（即知道却做很难做到，需要被提醒的）；最后希望文字能简短一些，最好是四个字朗朗上口一些。 昨晚睡觉的时候想了一会儿，还真的想到了特别符合上面几个需求的，即： 自律，勇敢 “自律” 的意思很明显，即 “自己约束自己，做该做的事”，而不是靠别人的督促。 “勇敢” 其实是比自律更进了一步，是 “对于自己认为是该做的事，即使可能会失败甚至付出巨大代价，也依然敢于去做”。 举个例子：如果我想减肥，那么能做到 ”少吃多运动“ 就是自律；如果我想升职加薪，那么如果有一个机会，我不知道能不能做好，但依然 ”勇于主动承担“ 就是勇敢。 自律与勇敢的区别是一个是失败了无损的，一个是失败了有损的。 另外的一个区别是：自律偏向于长期的，而勇敢更侧重于单次。 想到这里，我意识到刚才认为“勇敢是比自律更进了一步”并不准确。现在的我认为勇敢比自律难，或许以后会变为自律更难。 但无论如何，我认为 自律，勇敢 是值得我一直坚守的。","link":"/2022/01/04/%E4%BF%A1%E6%9D%A1/"}],"tags":[{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"prometheus","slug":"prometheus","link":"/tags/prometheus/"},{"name":"大监控","slug":"大监控","link":"/tags/%E5%A4%A7%E7%9B%91%E6%8E%A7/"},{"name":"翻译","slug":"翻译","link":"/tags/%E7%BF%BB%E8%AF%91/"}],"categories":[{"name":"life","slug":"life","link":"/categories/life/"},{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"}]}
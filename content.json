{"pages":[{"title":"about","text":"简单的程序猿. Email: whj_elite@163.com","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index-1.html"},{"title":"categories","text":"","link":"/categories/index.html"}],"posts":[{"title":"我为什么会惆怅","text":"中秋三天假，这么快就过去了 发现假期越长，临近假期结束时就越惆怅 大概是因为快乐而梦幻的时光这么快就结束，接下来又要面临挑战，反差太大，很难接受吧 不禁开始担心接下来的国庆节，在最后的一两天时，会有多失落啊 突然想起了《赤壁赋》： 于是饮酒乐甚，扣舷而歌之。 歌曰：“桂棹兮兰桨，击空明兮溯流光。 渺渺兮予怀，望美人兮天一方。” 客有吹洞箫者，倚歌而和之。 其声呜呜然，如怨如慕，如泣如诉，余音袅袅，不绝如缕。 舞幽壑之潜蛟，泣孤舟之嫠妇。 往往在欢乐的时光，想起难过的事情，会更难过吧 其实，我觉得文章中，苏子劝客的一番话，真的很扯淡 那为什么“客喜而笑，洗盏更酌”呢？ 面对如此真实的人生，不如此又能怎样呢，或许还不如享受当下 社会中，生活享受的人与生活煎熬的人，比例大概远远小于二与八 “肴核既尽，杯盘狼籍。相与枕藉乎舟中，不知东方之既白。” 看来我也是经常这样了，夜晚一个人在住处喝啤酒，看视频，真的是麻木的快乐，然后睡去…. 醒来时已经是第二天的九十点钟了 但是，麻木的快乐之后的生活，又会是怎样的呢, 该如何面对呢 ？ 这就是我为什么会惆怅","link":"/2019/09/15/2019-9-15/"},{"title":"谈&quot;道理&quot;","text":"这个话题其实起源于我的一次”自我反思”, 当时我又一次在想: 当前的生活状态自己满意吗? (答案显然是不那么满意的 要一直这样下去吗? (答案显然是不要 这个时候矛盾开始显现了: 既然我一直很笃定地认为 “不能再这样下去了”, 那为什么一直没有行动呢? 想到了王阳明的 “知行合一”, 我个人的理解大概就是: 知道做不到, 等于不知道. 所以我关于 “要一直这样下去吗” 的答案其实是: 是的, 要一直这样下去. 这让我变得疑惑了, 难道我不想变得更好吗? 我当然一直都很想啊, 怎么可能不想呢? 是我错了嘛还是他的观点是错的? 我一开始以为王阳明是在嘲笑或者讽刺那些 “知道却做不到” 的人, 后来我有了新的理解: “知行合一” 大概是基于结果论来说的, “一个道理你不知道” 与 “一个道理你知道却没做”, 它们的结果其实是一样的, 因为那个能改变结果的事情没有做, 所以才是 “知道做不到, 等于不知道”. 从这个角度来看的话, 其实 “想减肥就得少吃多动” 的道理我也根本不知道, 因为没能做到. 想起了 “后会无期” 中的经典台词: 听过很多道理,依然过不好这一生. 从这个角度看来, 不过是 “弱者的自我安慰” 罢了. 因为道理 “听过” 但不等于 “做过”, 做不到的道理也就等于没听过而已. 想到这里, 我觉得需要再重新审视一遍自己, 到底知道哪些 “道理” 了.","link":"/2021/01/11/%E8%B0%88%E9%81%93%E7%90%86/"},{"title":"Prometheus tsdb","text":"Prometheus 把监控数据存在本地磁盘的时间序列数据库中（ time series database, tsdb）, 同时也支持集成远程存储系统. Prometheus 的 tsdb 经历过两次大升级, 从 v1 升到 v2 , 从 v2 升到 v3, 其中每次升级都比原来的版本有着巨大的改善. 目前最新的版本是 v3 tsdb , 本文将对其进行介绍, 希望读者在读完本文后, 对 prometheus tsdb 整体设计能有比较清晰的认知、对自己感兴趣的实现细节能有一定的理解. 备注: 本文的内容是综合资料介绍以及个人理解总结出来的, 如果有理解不对或不准确的情况, 希望读者们能不吝指出. 数据库的选择/设计理念 &amp; Prometheus 的场景需求理念该选择哪款数据库, 或者一个数据库被设计成什么样, 取决与预期怎么使用它(场景). Prometheus 的场景样本点格式介绍1identifier -&gt; (t0, v0), (t1, v1), (t2, v2), (t3, v3), .... 其中, identifier 是一个 metric name 以及其所有标签的键值对, 例如： requests_total{path=”/status”, method=”GET”, instance=”10.0.0.1:80”} ti 表示时间点 vi 表示 ti 时刻该 identifier 的取值 metric name 也被视为一个标签, 用\\ _${metricName}_\\ 表示, 因此上述例子也可以表示为：{__name__=”requests_total”, path=”/status”, method=”GET”, instance=”10.0.0.1:80”} 场景需求 如上图所示, 其中, 横轴是时间 t, 纵轴是 identifier, 平面上的点是 v： 写需求 特别特别密集. 预期中, 一台 Prometheus 实例每秒钟应该能收集百万级别的样本点 只是纵向的写 读需求 相比于写, 读需求很少 对 Latency 要求较高 有按时间范围查询的需求, 且一般会涉及多个 identifier 的查询 越新的数据越有价值, 查询的需求也越高 k8s 环境下特有的现象—— series churn通常, metric 中都会有 instance 标签. 而在 k8s 环境下, 由于 pod 是经常变化的（比如滚动升级时）, 会导致「series churn」（不会翻译就不翻译了）, 如下图所示（即很多老 series 其实是不需要的）： 介绍完了 Prometheus 的场景特点以及对数据库的使用需求, 接下来介绍 Prometheus 所使用的 tsdb 是怎样做的. 整体架构 其中, (t, v) 即为采集的一个样本点（sample） Head block 在内存中 灰色的 block 在磁盘中（并且是不可变的） M-map 为磁盘中两个小时以内的数据在内存中的映射 WAL 是预写日志（Write-ahead logging） 接下来对监控样本点的生命周期进行简单介绍. 样本点的生命周期Prometheus 新采集的样本都会存到 Head block, 其中每一个 series 会存到唯一对应的压缩单元(即 chunk) 里. 为了防止 Prometheus 挂了导致内存中的数据丢失, 新采集到的数据还会写到预写日志中.如下图： 备注：样本点在存入 chunk 时, 通过 labels 的哈希值来获得或创建对应的 series chunk. 当 chunk 中存了 120 个样本或该 chunk 已满 2h 时, 将创建出一个新的 chunk, 老的 chunk 视为 “已满”. ps: 如果 15s 采集一次, 则每 30min 会满一次. 如下图所示: 红色的是新创建的 chunk, 黄色的是老的 chunk. 自 Prometheus v2.19.0 之后（我们目前使用的是 v2.20.0）, 当一个 chunk “已满” 时, 它就会被刷新到磁盘中, 并从磁盘中进行内存映射（memory-map）, 仅在内存中存储一个它的引用. 有了内存映射, 可以再需要的时候通过引用动态地将 chunk 加载到内存中, 这是操作系统提供的特性, 参考: https://en.wikipedia.org/wiki/Mmap. 当 Head 中的数据跨度达到 3h 时（mmap 中数据的时间跨度）, 则最久的两个小时的数据(即上图的 1~4)将被压缩成一个 persistent block. 此时, 相关的 WAL 和索引数据也被删除. 再看一次这个图： 每个 block 是按时间序列排序的. 当查询多个 block 中, 会从很多 block 中读出对应的数据, 然后再合并成一个整体的结果, 这个合并过程显然是有代价的. 因此引入了压缩(compaction)操作：即将一个或多个 block 合并成一个更大的 block. 在压缩的过程中还可以修改现有数据, 例如删除「已被删除」的数据, 或者重新构造样本块以提高查询性能. 压缩的时机与设定的步长有关: 假设 block 为保存 2h 的数据, 如果步长设置为 3, 则会将三个 2h 的合成一个 6h 的block, 将三个 6h 的合成一个 18h 的block. 当 block 中存储的数据达到了所设置的最大保留时间时, 它们即会被删除. 以上就是关于监控样本点的生命周期的简单介绍. 磁盘上的数据格式本节将分别对 Head Block 和 block 进行介绍. Head blockFile上文介绍的 mmap 中的 chunks 保存在名为 chunks_head 的目录下, 文件序列与 WAL 中的相似. 如下图: 12345678910data├── chunks_head| ├── 000001| └── 000002└── wal ├── checkpoint.000003 | ├── 000000 | └── 000001 ├── 000004 └── 000005 其中, 文件（比如上图中的 000001）的 最大 size 是 128M. 每个的文件格式如下所示: 123456789101112131415┌──────────────────────────────┐│ magic(0x0130BC91) &lt;4 byte&gt; │├──────────────────────────────┤│ version(1) &lt;1 byte&gt; │├──────────────────────────────┤│ padding(0) &lt;3 byte&gt; │├──────────────────────────────┤│ ┌──────────────────────────┐ ││ │ Chunk 1 │ ││ ├──────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────┤ ││ │ Chunk N │ ││ └──────────────────────────┘ │└──────────────────────────────┘ 其中. magic number 是可以唯一标识一个文件时 head_chunk 的数字 (类似 Java 中的咖啡宝贝..) version 告诉我们如何解码文件中的 chunks (version 怎么告诉我们如何解码？version 其实是编码/格式的版本) padding 是为了将来可能需要的选项而预留出来的 备注：magic 在接下来其他的数据格式中会多次出现, 用途一致, 就不赘述了. Chunk一个 chunk 的格式如下所示： 123┌─────────────────────┬───────────────────────┬───────────────────────┬───────────────────┬───────────────┬──────────────┬────────────────┐| series ref &lt;8 byte&gt; | mint &lt;8 byte, uint64&gt; | maxt &lt;8 byte, uint64&gt; | encoding &lt;1 byte&gt; | len &lt;uvarint&gt; | data &lt;bytes&gt; │ CRC32 &lt;4 byte&gt; │└─────────────────────┴───────────────────────┴───────────────────────┴───────────────────┴───────────────┴──────────────┴────────────────┘ 其中, series ref 是用于访问内存中的序列的 id, 即上文中 mmap 中的引用 mint 是该 chunk 中 series 的最小时间戳 max 是该 chunk 中 series 的最大时间戳 encoding 是压缩该 chunk 时使用的编码 len 是此后的字节数 data 是压缩后的数据 CRC32 是用于检查数据完整性的校验和 Head Block 通过 series ref, 以及 mint、maxt 就可以实现不访问磁盘就选择 chunk. 其中, ref 是 8 bytes, 前 4 个字节告诉了 chunk 存在哪个文件中（file number）， 后四个字节告诉了 chunk 在该文件中的偏移量. Persistent Block1234567891011121314151617data├── 01EM6Q6A1YPX4G9TEB20J22B2R| ├── chunks| | ├── 000001| | └── 000002| ├── index| ├── meta.json| └── tombstones├── chunks_head| ├── 000001| └── 000002└── wal ├── checkpoint.000003 | ├── 000000 | └── 000001 ├── 000004 └── 000005 上图中的 01EM6Q6A1YPX4G9TEB20J22B2R 即是一个 Persistent Block. 其中, meta.json：block 的元信息 chunks：chunk 的原始数据 index：block 的索引 tombstones：删除标记, 用于查询该 block 时排除样本 01EM6Q6A1YPX4G9TEB20J22B2R：block id （与 UUID 主要的区别是它是字典序的, 见https://github.com/oklog/ulid） 接下来分别进行介绍. meta.jsonmeta 中包含了整个 block 所需的所有元数据, 如下图： 123456789101112131415161718{ &quot;ulid&quot;: &quot;01EM6Q6A1YPX4G9TEB20J22B2R&quot;, &quot;minTime&quot;: 1602237600000, &quot;maxTime&quot;: 1602244800000, &quot;stats&quot;: { &quot;numSamples&quot;: 553673232, &quot;numSeries&quot;: 1346066, &quot;numChunks&quot;: 4440437 }, &quot;compaction&quot;: { &quot;level&quot;: 1, &quot;sources&quot;: [ &quot;01EM65SHSX4VARXBBHBF0M0FDS&quot;, &quot;01EM6GAJSYWSQQRDY782EA5ZPN&quot; ] }, &quot;version&quot;: 1} 其中, version：索引格式的版本，告诉我们如何解析该 meta 文件 ulid：尽管该 block 的目录名是 ULID, 但是实际上已 meta 中的 ulid 为准，目录名可以是任何名称. minTime/maxTime：该 block 中所有 chunk 的 min 和 max 时间戳 stats：该 block 中存储的时间序列、样本和 chunk 的数量 compaction：该 block 的历史 level：该 block 多少代了 sources：由哪些 blocks 合并而成, 如果是从 Head block 创建来的, 则 sources 设置为自己的 ULID Chunks123456789101112131415┌──────────────────────────────┐│ magic(0x85BD40DD) &lt;4 byte&gt; │├──────────────────────────────┤│ version(1) &lt;1 byte&gt; │├──────────────────────────────┤│ padding(0) &lt;3 byte&gt; │├──────────────────────────────┤│ ┌──────────────────────────┐ ││ │ Chunk 1 │ ││ ├──────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────┤ ││ │ Chunk N │ ││ └──────────────────────────┘ │└──────────────────────────────┘ 与 Head 中的文件格式差不多, 不赘述了. 但有个区别是 Head 中的 file 最大 size 是 128M, 这里的 file 最大是 512M. 每个 chunk 的格式如下图所示： 123┌───────────────┬───────────────────┬──────────────┬────────────────┐│ len &lt;uvarint&gt; │ encoding &lt;1 byte&gt; │ data &lt;bytes&gt; │ CRC32 &lt;4 byte&gt; │└───────────────┴───────────────────┴──────────────┴────────────────┘ 与 head_chunk 差不多, 区别是少了 series ref、mint、maxt. 在 Head_chunk 中需要这些附加信息是为了 prometheus 重启时能够创建内存索引, 但是在持久化 block 中, 这些信息在 index 文件中存储了, 因此不再需要.同样通过 reference 来访问这些 chunk. indexindex 是倒排索引, 它包含了查询该 block 所需要的所有信息. 它不与任何其它 block 或外部实体共享数据, 这使得可以在没有任何依赖的情况下读取/查询该 block.(这个结构比较复杂, 但不要慌 : )) 它的宏观视图如下所示： 123456789101112131415161718192021222324252627┌────────────────────────────┬─────────────────────┐│ magic(0xBAAAD700) &lt;4b&gt; │ version(1) &lt;1 byte&gt; │├────────────────────────────┴─────────────────────┤│ ┌──────────────────────────────────────────────┐ ││ │ Symbol Table │ ││ ├──────────────────────────────────────────────┤ ││ │ Series │ ││ ├──────────────────────────────────────────────┤ ││ │ Label Index 1 │ ││ ├──────────────────────────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────────────────────────┤ ││ │ Label Index N │ ││ ├──────────────────────────────────────────────┤ ││ │ Postings 1 │ ││ ├──────────────────────────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────────────────────────┤ ││ │ Postings N │ ││ ├──────────────────────────────────────────────┤ ││ │ Label Offset Table │ ││ ├──────────────────────────────────────────────┤ ││ │ Postings Offset Table │ ││ ├──────────────────────────────────────────────┤ ││ │ TOC │ ││ └──────────────────────────────────────────────┘ │└──────────────────────────────────────────────────┘ 其中, magic：用来唯一标识某个文件是 index 文件 version：告诉我们如何解析该文件 TOC：是该 index 文件的入口处（就像目录一样, 记录了各部分的页码） TOC123456789101112131415┌─────────────────────────────────────────┐│ ref(symbols) &lt;8b&gt; │ -&gt; Symbol Table├─────────────────────────────────────────┤│ ref(series) &lt;8b&gt; │ -&gt; Series├─────────────────────────────────────────┤│ ref(label indices start) &lt;8b&gt; │ -&gt; Label Index 1├─────────────────────────────────────────┤│ ref(label offset table) &lt;8b&gt; │ -&gt; Label Offset Table├─────────────────────────────────────────┤│ ref(postings start) &lt;8b&gt; │ -&gt; Postings 1├─────────────────────────────────────────┤│ ref(postings offset table) &lt;8b&gt; │ -&gt; Postings Offset Table├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt; │└─────────────────────────────────────────┘ 格式如上图所示, 主要是告诉我们各索引开始的位置. TOC 是固定大小的，因此文件的最后 52 个字节就是 TOC. Symbol Table符号表,记录了所有 series 的标签和值的字符串的非重复有序列表.比如 一个 series 是 {a=”y”, x=”b”}, 则符号会是 “a”, “b”, “x”, “y” . 12345678910111213┌────────────────────┬─────────────────────┐│ len &lt;4b&gt; │ #symbols &lt;4b&gt; │├────────────────────┴─────────────────────┤│ ┌──────────────────────┬───────────────┐ ││ │ len(str_1) &lt;uvarint&gt; │ str_1 &lt;bytes&gt; │ ││ ├──────────────────────┴───────────────┤ ││ │ . . . │ ││ ├──────────────────────┬───────────────┤ ││ │ len(str_n) &lt;uvarint&gt; │ str_n &lt;bytes&gt; │ ││ └──────────────────────┴───────────────┘ │├──────────────────────────────────────────┤│ CRC32 &lt;4b&gt; │└──────────────────────────────────────────┘ len：该部分的字节数symbols：符号的数量str_i：utf8 编码的字符串, 每个字符串前都有 len 前缀; 随后是字符串的原始值索引中的其他部分可以为任何字符串引用此符号表, 由此减小 index 的大小. （通过偏移量 str_i 引用, 当需要实际的字符串时, 则通过偏移量从表中获取） Series123456789┌───────────────────────────────────────┐│ ┌───────────────────────────────────┐ ││ │ series_1 │ ││ ├───────────────────────────────────┤ ││ │ . . . │ ││ ├───────────────────────────────────┤ ││ │ series_n │ ││ └───────────────────────────────────┘ │└───────────────────────────────────────┘ 此部分存了当前 block 中所有 series 的信息, 按照标签的字典序排序. 每个 series 都是 16 byte 对齐的, 使得 series 开始处的偏移量能够被 16 整除. 因此,将 series 的 id 设置为 offset/16, offset 指向 series 的开头. 每当要访问某个 series 时, 可以直接通过 id * 16 来获取在 index 中的位置. Label Offset Table &amp; Label Index i这两个是耦合的, 因此应该放在一起介绍. 但是, 目前这两个已经不再使用, 只是为了向后兼容而编写的. 所以本文暂且没有介绍. Postings Offset Table &amp; Postings iPostings iposting 其实就是 series id. (之所以叫 posting 其实是因为在倒排索引的 “世界” 里, 文档 id 常被成为 posting, 而在当前的场景下, 一个 series 可以被视为一个文档, 因此把 series id 当做 posting.) 单个 posting 其实代表了一个 posting list, 其格式如下所示: 12345678910111213┌────────────────────┬────────────────────┐│ len &lt;4b&gt; │ #entries &lt;4b&gt; │├────────────────────┴────────────────────┤│ ┌─────────────────────────────────────┐ ││ │ ref(series_1) &lt;4b&gt; │ ││ ├─────────────────────────────────────┤ ││ │ ... │ ││ ├─────────────────────────────────────┤ ││ │ ref(series_n) &lt;4b&gt; │ ││ └─────────────────────────────────────┘ │├─────────────────────────────────────────┤│ CRC32 &lt;4b&gt; │└─────────────────────────────────────────┘ 其中, len 和 CRC32 的作用大家都已经很熟悉了. entries 是该 list 中的 posting 数量; 其次是 entries 个有序的 posting（即 series id, 即引用）. posting list 中存储的内容介绍： 假设有两个时间序列: {a=”b”, x=”y1”} with series ID 120 {a=”b”, x=”y2”} with series ID 145 可以看到 a=”b” 出现在两个 series 中, ; 而 x=”y1”, x=”y2” 分别各自出现在一个 series 中. 此时 posting list 中会存: posting 1： // a=”b” 在两个 series 都出现了 120 145 posting 2：//x =”y1” 120 posting 3: //x =”y2” 145 Postings Offset Table12345678910111213141516┌─────────────────────┬──────────────────────┐│ len &lt;4b&gt; │ #entries &lt;4b&gt; │├─────────────────────┴──────────────────────┤│ ┌────────────────────────────────────────┐ ││ │ n = 2 &lt;1b&gt; │ ││ ├──────────────────────┬─────────────────┤ ││ │ len(name) &lt;uvarint&gt; │ name &lt;bytes&gt; │ ││ ├──────────────────────┼─────────────────┤ ││ │ len(value) &lt;uvarint&gt; │ value &lt;bytes&gt; │ ││ ├──────────────────────┴─────────────────┤ ││ │ offset &lt;uvarint64&gt; │ ││ └────────────────────────────────────────┘ ││ . . . │├────────────────────────────────────────────┤│ CRC32 &lt;4b&gt; │└────────────────────────────────────────────┘ 其中, len 和 CRC32 的作用大家都已经很熟悉了. entries 是该表中的条目数. n 永远是 2, 代表了接下来字符串的数量（label name 和 label value 俩字符串）. 接下来是 label name 和 label value 的原始值. 由于标签对通常并不多, 因此能够负担得起在此处存储原始字符串，从而避免间接访问符号表（符号表的主要用途在于被 Series 部分使用）. PS：我们公司目前的标签对还是很多的. offset 代表了该键值对在 postings list 中的偏移量. 以上述例子中, name=”a”, value=”b” 的偏移量将指向 posting list 中的 [120, 145] name=”x”, value=”y1” 的偏移量将指向 posting list 中的 [120] Postings Offset Table 中的条目是根据 label name 和 label value 排序的, 因此可以对所需的标签对进行二分查找（这也是此处存储实际字符串以便于更快访问标签值的另一个原因）. postings list 与 postings offset table 构成了倒排索引. tombstones Tombstones（墓碑） 是删除标记, 它告诉我们在读取/查询时可以忽略哪个 time series 的哪段时间范围. 12345678910111213┌────────────────────────────┬─────────────────────┐│ magic(0x0130BA30) &lt;4b&gt; │ version(1) &lt;1 byte&gt; │├────────────────────────────┴─────────────────────┤│ ┌──────────────────────────────────────────────┐ ││ │ Tombstone 1 │ ││ ├──────────────────────────────────────────────┤ ││ │ ... │ ││ ├──────────────────────────────────────────────┤ ││ │ Tombstone N │ ││ ├──────────────────────────────────────────────┤ ││ │ CRC&lt;4b&gt; │ ││ └──────────────────────────────────────────────┘ │└──────────────────────────────────────────────────┘ magic、version、CRC 的作用大家都很熟悉了. Tombstone 的格式如下： 123┌────────────────────────┬─────────────────┬─────────────────┐│ series ref &lt;uvarint64&gt; │ mint &lt;varint64&gt; │ maxt &lt;varint64&gt; │└────────────────────────┴─────────────────┴─────────────────┘ 其它还有一些内容也属于 tsdb 中需要了解的范畴, 比如数据压缩的方法等, 但不是目前必须要知道的内容, 因此本文中暂时没有介绍, 感兴趣的话可以自行去了解. 结合上述分析和部分源码, 查询 tsdb 时发生了什么？前置介绍一个 Block 即是一个 NewBlockQuerier.见下 1424 行. 1234567891011121314151617181920212223242526272829303132// Querier returns a new querier over the data partition for the given time range.func (db *DB) Querier(_ context.Context, mint, maxt int64) (storage.Querier, error) { var blocks []BlockReader db.mtx.RLock() defer db.mtx.RUnlock() for _, b := range db.blocks { if b.OverlapsClosedInterval(mint, maxt) { blocks = append(blocks, b) } } if maxt &gt;= db.head.MinTime() { blocks = append(blocks, NewRangeHead(db.head, mint, maxt)) } blockQueriers := make([]storage.Querier, 0, len(blocks)) for _, b := range blocks { q, err := NewBlockQuerier(b, mint, maxt) //为 block 创建 NewBlockQuerier, 构造函数见下一个代码块 if err == nil { blockQueriers = append(blockQueriers, q) continue } // If we fail, all previously opened queriers must be closed. for _, q := range blockQueriers { // TODO(bwplotka): Handle error. _ = q.Close() } return nil, errors.Wrapf(err, &quot;open querier for block %s&quot;, b) } return storage.NewMergeQuerier(blockQueriers, nil, storage.ChainedSeriesMerge), nil} 12345678// NewBlockQuerier returns a querier against the block reader and requested min and max time range.func NewBlockQuerier(b BlockReader, mint, maxt int64) (storage.Querier, error) { q, err := newBlockBaseQuerier(b, mint, maxt) // newBlockBaseQuerier 构造函数见下一个代码块 if err != nil { return nil, err } return &amp;blockQuerier{blockBaseQuerier: q}, nil} 12345678910111213141516171819202122232425262728func newBlockBaseQuerier(b BlockReader, mint, maxt int64) (*blockBaseQuerier, error) { indexr, err := b.Index() if err != nil { return nil, errors.Wrap(err, &quot;open index reader&quot;) } chunkr, err := b.Chunks() if err != nil { indexr.Close() return nil, errors.Wrap(err, &quot;open chunk reader&quot;) } tombsr, err := b.Tombstones() if err != nil { indexr.Close() chunkr.Close() return nil, errors.Wrap(err, &quot;open tombstone reader&quot;) } if tombsr == nil { tombsr = tombstones.NewMemTombstones() } return &amp;blockBaseQuerier{ mint: mint, maxt: maxt, index: indexr, chunks: chunkr, tombstones: tombsr, }, nil} Querier 通过调用 Select 方法返回 series set123456789// Querier provides querying access over time series data of a fixed time range.type Querier interface { LabelQuerier // Select returns a set of series that matches the given label matchers. // Caller can specify if it requires returned series to be sorted. Prefer not requiring sorting for better performance. // It allows passing hints that can help in optimising select, but it&apos;s up to implementation how this is used if used at all. Select(sortSeries bool, hints *SelectHints, matchers ...*labels.Matcher) SeriesSet} 在 Select 时, 会根据 PromQL 中的标签条件进行匹配, 最终调用 Postings 方法获得 series ids12345678910111213141516171819202122func (q *blockQuerier) Select(sortSeries bool, hints *storage.SelectHints, ms ...*labels.Matcher) storage.SeriesSet { mint := q.mint maxt := q.maxt p, err := PostingsForMatchers(q.index, ms...) // 在这一步即获得了 postings, 即 series ids, 见下一个代码块 if err != nil { return storage.ErrSeriesSet(err) } if sortSeries { p = q.index.SortedPostings(p) } if hints != nil { mint = hints.Start maxt = hints.End if hints.Func == &quot;series&quot; { // When you&apos;re only looking up metadata (for example series API), you don&apos;t need to load any chunks. return newBlockSeriesSet(q.index, newNopChunkReader(), q.tombstones, p, mint, maxt) } } return newBlockSeriesSet(q.index, q.chunks, q.tombstones, p, mint, maxt)} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// PostingsForMatchers assembles a single postings iterator against the index reader// based on the given matchers. The resulting postings are not ordered by series.func PostingsForMatchers(ix IndexReader, ms ...*labels.Matcher) (index.Postings, error) { var its, notIts []index.Postings // See which label must be non-empty. // Optimization for case like {l=~&quot;.&quot;, l!=&quot;1&quot;}. labelMustBeSet := make(map[string]bool, len(ms)) for _, m := range ms { if !m.Matches(&quot;&quot;) { labelMustBeSet[m.Name] = true } } for _, m := range ms { if labelMustBeSet[m.Name] { // If this matcher must be non-empty, we can be smarter. matchesEmpty := m.Matches(&quot;&quot;) isNot := m.Type == labels.MatchNotEqual || m.Type == labels.MatchNotRegexp if isNot &amp;&amp; matchesEmpty { // l!=&quot;foo&quot; // If the label can&apos;t be empty and is a Not and the inner matcher // doesn&apos;t match empty, then subtract it out at the end. inverse, err := m.Inverse() if err != nil { return nil, err } it, err := postingsForMatcher(ix, inverse) //见下一个代码块 if err != nil { return nil, err } notIts = append(notIts, it) } else if isNot &amp;&amp; !matchesEmpty { // l!=&quot;&quot; // If the label can&apos;t be empty and is a Not, but the inner matcher can // be empty we need to use inversePostingsForMatcher. inverse, err := m.Inverse() if err != nil { return nil, err } it, err := inversePostingsForMatcher(ix, inverse) //见下下个代码块 if err != nil { return nil, err } its = append(its, it) } else { // l=&quot;a&quot; // Non-Not matcher, use normal postingsForMatcher. it, err := postingsForMatcher(ix, m) //见下一个代码块 if err != nil { return nil, err } its = append(its, it) } } else { // l=&quot;&quot; // If the matchers for a labelname selects an empty value, it selects all // the series which don&apos;t have the label name set too. See: // https://github.com/prometheus/prometheus/issues/3575 and // https://github.com/prometheus/prometheus/pull/3578#issuecomment-351653555 it, err := inversePostingsForMatcher(ix, m) //见下下个代码块 if err != nil { return nil, err } notIts = append(notIts, it) } } // If there&apos;s nothing to subtract from, add in everything and remove the notIts later. if len(its) == 0 &amp;&amp; len(notIts) != 0 { k, v := index.AllPostingsKey() allPostings, err := ix.Postings(k, v) //最终都会调用 Postings 方法 if err != nil { return nil, err } its = append(its, allPostings) } it := index.Intersect(its...) for _, n := range notIts { it = index.Without(it, n) } return it, nil} 12345678910111213141516171819202122232425262728293031323334353637383940414243func postingsForMatcher(ix IndexReader, m *labels.Matcher) (index.Postings, error) { // This method will not return postings for missing labels. // Fast-path for equal matching. if m.Type == labels.MatchEqual { return ix.Postings(m.Name, m.Value) //最终都会调用 Postings 方法 } // Fast-path for set matching. if m.Type == labels.MatchRegexp { setMatches := findSetMatches(m.GetRegexString()) if len(setMatches) &gt; 0 { sort.Strings(setMatches) return ix.Postings(m.Name, setMatches...) } } vals, err := ix.LabelValues(m.Name) if err != nil { return nil, err } var res []string lastVal, isSorted := &quot;&quot;, true for _, val := range vals { if m.Matches(val) { res = append(res, val) if isSorted &amp;&amp; val &lt; lastVal { isSorted = false } lastVal = val } } if len(res) == 0 { return index.EmptyPostings(), nil } if !isSorted { sort.Strings(res) } return ix.Postings(m.Name, res...)} 123456789101112131415161718192021222324// inversePostingsForMatcher returns the postings for the series with the label name set but not matching the matcher.func inversePostingsForMatcher(ix IndexReader, m *labels.Matcher) (index.Postings, error) { vals, err := ix.LabelValues(m.Name) if err != nil { return nil, err } var res []string lastVal, isSorted := &quot;&quot;, true for _, val := range vals { if !m.Matches(val) { res = append(res, val) if isSorted &amp;&amp; val &lt; lastVal { isSorted = false } lastVal = val } } if !isSorted { sort.Strings(res) } return ix.Postings(m.Name, res...)} 正式开始吧如 “前置介绍” 中所说, 在查询时最终都会调用 block 的 postings 方法. 接下来分别对 Head Block 中的 postings 方法和 Persistent Block 中的 postings 方法进行介绍. Head#Postings12345678// Postings returns the postings list iterator for the label pairs.func (h *headIndexReader) Postings(name string, values ...string) (index.Postings, error) { res := make([]index.Postings, 0, len(values)) for _, value := range values { res = append(res, h.head.postings.Get(name, value)) //直接通过 postings.Get 获得 } return index.Merge(res...), nil} 123456789101112131415// Get returns a postings list for the given label pair.func (p *MemPostings) Get(name, value string) Postings { var lp []uint64 p.mtx.RLock() l := p.m[name] if l != nil { lp = l[value] } p.mtx.RUnlock() if lp == nil { return EmptyPostings() } return newListPostings(lp...)} 123456789// MemPostings holds postings list for series ID per label pair. They may be written// to out of order.// ensureOrder() must be called once before any reads are done. This allows for quick// unordered batch fills on startup.type MemPostings struct { mtx sync.RWMutex m map[string]map[string][]uint64 ordered bool} 总结：Head 的 Postings 方法很简单, 直接通过 mmap 即可获得某个标签键值对的 postings. Block#Postings1234567func (r blockIndexReader) Postings(name string, values ...string) (index.Postings, error) { p, err := r.ir.Postings(name, values...) // 调用 Index 的 Postings if err != nil { return p, errors.Wrapf(err, &quot;block: %s&quot;, r.b.Meta().ULID) } return p, nil} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104func (r *Reader) Postings(name string, values ...string) (Postings, error) { if r.version == FormatV1 { // 我们现在应该是 V2, 可忽略 e, ok := r.postingsV1[name] if !ok { return EmptyPostings(), nil } res := make([]Postings, 0, len(values)) for _, v := range values { postingsOff, ok := e[v] if !ok { continue } // Read from the postings table. d := encoding.NewDecbufAt(r.b, int(postingsOff), castagnoliTable) _, p, err := r.dec.Postings(d.Get()) if err != nil { return nil, errors.Wrap(err, &quot;decode postings&quot;) } res = append(res, p) } return Merge(res...), nil } e, ok := r.postings[name] // Reader 的内容见下一个代码块, 即获得该 label 在 offset table 中的开始位置 if !ok { return EmptyPostings(), nil } if len(values) == 0 { return EmptyPostings(), nil } res := make([]Postings, 0, len(values)) skip := 0 valueIndex := 0 for valueIndex &lt; len(values) &amp;&amp; values[valueIndex] &lt; e[0].value { // 遍历直至找到开始的位置. // 根据上文的宏观介绍, offset table 中 label 的 key 和 value 都是有序的 // 因此 values[valueIndex] &lt; e[0].value 即代表查询的标签值在当前 block 中不存在/未命中 // Discard values before the start. valueIndex++ } for valueIndex &lt; len(values) { value := values[valueIndex] //二分查找 i := sort.Search(len(e), func(i int) bool { return e[i].value &gt;= value }) if i == len(e) { // We&apos;re past the end. break } if i &gt; 0 &amp;&amp; e[i].value != value { // Need to look from previous entry. i-- } // Don&apos;t Crc32 the entire postings offset table, this is very slow // so hope any issues were caught at startup. d := encoding.NewDecbufAt(r.b, int(r.toc.PostingsTable), nil) d.Skip(e[i].off) // Iterate on the offset table. var postingsOff uint64 // The offset into the postings table. for d.Err() == nil { if skip == 0 { // These are always the same number of bytes, // and it&apos;s faster to skip than parse. skip = d.Len() d.Uvarint() // Keycount. d.UvarintBytes() // Label name. skip -= d.Len() } else { d.Skip(skip) } v := d.UvarintBytes() // Label value. postingsOff = d.Uvarint64() // Offset. for string(v) &gt;= value { if string(v) == value { // 如果标签值匹配上了 // Read from the postings table. d2 := encoding.NewDecbufAt(r.b, int(postingsOff), castagnoliTable) _, p, err := r.dec.Postings(d2.Get()) // 解码 if err != nil { return nil, errors.Wrap(err, &quot;decode postings&quot;) } res = append(res, p) // postings 加入 result list } valueIndex++ if valueIndex == len(values) { break } value = values[valueIndex] } if i+1 == len(e) || value &gt;= e[i+1].value || valueIndex == len(values) { // Need to go to a later postings offset entry, if there is one. break } } if d.Err() != nil { return nil, errors.Wrap(d.Err(), &quot;get postings offset entry&quot;) } } return Merge(res...), nil} 123456789101112131415161718192021type Reader struct { b ByteSlice toc *TOC // Close that releases the underlying resources of the byte slice. c io.Closer // Map of LabelName to a list of some LabelValues&apos;s position in the offset table. // The first and last values for each name are always present. postings map[string][]postingOffset // For the v1 format, labelname -&gt; labelvalue -&gt; offset. postingsV1 map[string]map[string]uint64 symbols *Symbols nameSymbols map[uint32]string // Cache of the label name symbol lookups, // as there are not many and they are half of all lookups. dec *Decoder version int} 总结： 通过 postings[name] 获得 label name 所对应的 values 的在 offset table 中开始的位置 首先根据上述 “开始的位置” 的标签的值过滤掉未命中的 label values（因为有序） 遍历所有需要查询的标签值 在 offset table 中进行二分查找, 找到当前标签值在 offset table 中的上界（上界是标签值, 或者前一个是标签值, 或者 miss） 通过 toc 找到 posting offet table， 通过上边找到的 offset 获得对应的 series ids 通过 series ids 反解出原始的标签值 原始标签值与要查找的标签值对比 如果相等则把该 series id 加入到 res 中 不相等则说明二分查找 miss merge res 参考资料 https://prometheus.io/docs/prometheus/latest/storage/ https://fabxc.org/tsdb/ https://ganeshvernekar.com/blog/prometheus-tsdb-the-head-block https://ganeshvernekar.com/blog/prometheus-tsdb-persistent-block-and-its-index https://github.com/prometheus/prometheus/blob/master/tsdb/docs/format/index.md https://github.com/prometheus/prometheus/blob/master/tsdb/head.go https://github.com/prometheus/prometheus/blob/2c4a4548a8382f7c8966dbfda37f34c43151e316/storage/series.go https://github.com/prometheus/prometheus/tree/a282d2509971174301408c5a5f96946c478dfb0f/tsdb/index","link":"/2020/11/29/Prometheus-tsdb/"}],"tags":[{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"prometheus","slug":"prometheus","link":"/tags/prometheus/"},{"name":"大监控","slug":"大监控","link":"/tags/%E5%A4%A7%E7%9B%91%E6%8E%A7/"}],"categories":[{"name":"life","slug":"life","link":"/categories/life/"},{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"}]}